{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T08:34:46.133563Z",
     "start_time": "2021-11-15T08:34:42.817521Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T08:34:54.508671Z",
     "start_time": "2021-11-15T08:34:46.135564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbigshanedogg\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/bigshanedogg/jigsaw/runs/4lxqafhc\" target=\"_blank\">rural-cosmos-19</a></strong> to <a href=\"https://wandb.ai/bigshanedogg/jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776szo2054p6\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "project_name = \"jigsaw\"\n",
    "wandb.init(project=project_name)\n",
    "anony = None\n",
    "\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "#     wandb.login(key=api_key)\n",
    "#     anony = None\n",
    "# except:\n",
    "#     anony = \"must\"\n",
    "#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n",
    "    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "HASH_NAME = id_generator(size=12)\n",
    "print(HASH_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T08:35:02.516466Z",
     "start_time": "2021-11-15T08:34:54.511643Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 2021,\n",
    "    \"epochs\": 3,\n",
    "    \"model_name\": \"roberta-base\",\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 32,\n",
    "    \"max_length\": 128,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"num_classes\": 1,\n",
    "    \"margin\": 0.5,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"hash_name\": HASH_NAME\n",
    "}\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "CONFIG['group'] = f'{HASH_NAME}-Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T08:35:02.531435Z",
     "start_time": "2021-11-15T08:35:02.518433Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T08:35:17.301046Z",
     "start_time": "2021-11-15T08:35:17.081882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T08:35:03.343416Z",
     "start_time": "2021-11-15T08:34:42.823Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.worker)):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T03:20:09.703645Z",
     "start_time": "2021-11-15T03:20:09.690648Z"
    }
   },
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.more_toxic = df['more_toxic'].values\n",
    "        self.less_toxic = df['less_toxic'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        more_toxic = self.more_toxic[index]\n",
    "        less_toxic = self.less_toxic[index]\n",
    "        inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                                more_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                                less_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        target = 1\n",
    "        \n",
    "        more_toxic_ids = inputs_more_toxic['input_ids']\n",
    "        more_toxic_mask = inputs_more_toxic['attention_mask']\n",
    "        \n",
    "        less_toxic_ids = inputs_less_toxic['input_ids']\n",
    "        less_toxic_mask = inputs_less_toxic['attention_mask']\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n",
    "            'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n",
    "            'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n",
    "            'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n",
    "            'target': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T03:20:09.718678Z",
     "start_time": "2021-11-15T03:20:09.706647Z"
    }
   },
   "outputs": [],
   "source": [
    "class JigsawModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(JigsawModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "        out = self.drop(out[1])\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T03:20:09.733671Z",
     "start_time": "2021-11-15T03:20:09.720648Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss\n",
    "from torch import Tensor\n",
    "\n",
    "class VariableMarginRankingLoss(_Loss):\n",
    "    __constants__ = ['reduction']\n",
    "\n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(MarginRankingLoss, self).__init__(size_average, reduce, reduction)\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, input1: Tensor, input2: Tensor, target: Tensor, margin: float = 0.) -> Tensor:\n",
    "        return F.margin_ranking_loss(input1, input2, target, margin=margin, reduction=self.reduction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T03:20:09.748648Z",
     "start_time": "2021-11-15T03:20:09.734677Z"
    }
   },
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=CONFIG['margin'])(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T03:20:09.763677Z",
     "start_time": "2021-11-15T03:20:09.751650Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n",
    "        \n",
    "        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n",
    "        \n",
    "        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T03:20:09.778674Z",
     "start_time": "2021-11-15T03:20:09.764646Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    # To automatically log gradients\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(\"train\")\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        print(\"val\")\n",
    "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        \n",
    "        # Log the metrics\n",
    "        wandb.log({\"Train Loss\": train_epoch_loss})\n",
    "        wandb.log({\"Valid Loss\": val_epoch_loss})\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            run.summary[\"Best Loss\"] = best_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T03:20:09.793671Z",
     "start_time": "2021-11-15T03:20:09.779646Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = JigsawDataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_dataset = JigsawDataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=0, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=0, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:00:06.533345Z",
     "start_time": "2021-11-15T03:20:09.794674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m====== Fold: 0 ======\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1j0vqmx5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 33244... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">major-lake-16</strong>: <a href=\"https://wandb.ai/bigshanedogg/jigsaw/runs/1j0vqmx5\" target=\"_blank\">https://wandb.ai/bigshanedogg/jigsaw/runs/1j0vqmx5</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211115_121954-1j0vqmx5\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1j0vqmx5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/bigshanedogg/jigsaw/runs/3u8bi8a7\" target=\"_blank\">9s0ly97dnlgn-fold-0</a></strong> to <a href=\"https://wandb.ai/bigshanedogg/jigsaw\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 752/752 [12:08<00:00,  1.03it/s, Epoch=1, LR=5.11e-5, Train_Loss=0.365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 189/189 [00:59<00:00,  3.17it/s, Epoch=1, LR=5.11e-5, Valid_Loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (inf ---> 0.3399098007158756)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 752/752 [12:11<00:00,  1.03it/s, Epoch=2, LR=1.02e-6, Train_Loss=0.361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 189/189 [00:59<00:00,  3.18it/s, Epoch=2, LR=1.02e-6, Valid_Loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 752/752 [12:12<00:00,  1.03it/s, Epoch=3, LR=4.86e-5, Train_Loss=0.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 189/189 [00:59<00:00,  3.17it/s, Epoch=3, LR=4.86e-5, Valid_Loss=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 0h 39m 34s\n",
      "Best Loss: 0.3399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35564... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▇▁</td></tr><tr><td>Valid Loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Loss</td><td>0.33991</td></tr><tr><td>Train Loss</td><td>0.33006</td></tr><tr><td>Valid Loss</td><td>0.36193</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">9s0ly97dnlgn-fold-0</strong>: <a href=\"https://wandb.ai/bigshanedogg/jigsaw/runs/3u8bi8a7\" target=\"_blank\">https://wandb.ai/bigshanedogg/jigsaw/runs/3u8bi8a7</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211115_122009-3u8bi8a7\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for fold in range(0, CONFIG['n_fold']):\n",
    "for fold in range(0, 1):\n",
    "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
    "    run = wandb.init(project='Jigsaw', \n",
    "                     config=CONFIG,\n",
    "                     job_type='Train',\n",
    "                     group=CONFIG['group'],\n",
    "                     tags=['roberta-base', f'{HASH_NAME}', 'margin-loss'],\n",
    "                     name=f'{HASH_NAME}-fold-{fold}',\n",
    "                     anonymous='must')\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
    "    \n",
    "    model = JigsawModel(CONFIG['model_name'])\n",
    "    model.to(CONFIG['device'])\n",
    "    \n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    \n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "    \n",
    "    run.finish()\n",
    "    \n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:31:29.866166Z",
     "start_time": "2021-11-15T04:31:29.846164Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:31:13.619080Z",
     "start_time": "2021-11-15T04:31:13.585077Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1266e29a465e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstate_dict_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./models/jigsaw-toxic-severity-rating/roberta-baseline/model_state_dict.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"state_dict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "state_dict_path = \"./models/jigsaw-toxic-severity-rating/roberta-baseline/model_state_dict.pt\"\n",
    "checkpoint = dict()\n",
    "checkpoint[\"state_dict\"] = state_dict = {k: torch.clone(v).to(\"cpu\") for k, v in model.state_dict().items()}\n",
    "torch.save(checkpoint, state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
